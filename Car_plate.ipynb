{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":533203,"sourceType":"datasetVersion","datasetId":253602},{"sourceId":1203932,"sourceType":"datasetVersion","datasetId":686454},{"sourceId":3753395,"sourceType":"datasetVersion","datasetId":2224491},{"sourceId":7133049,"sourceType":"datasetVersion","datasetId":4115649}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport numpy as np \nimport pandas as pd \nfrom bs4 import BeautifulSoup \nimport os\nimport shutil\nimport glob\nimport yaml\nimport torch\n!pip install easyocr -qq\nimport easyocr\nimport cv2 as cv\nimport matplotlib.pyplot as plt\nimport easyocr\n%matplotlib inline\nimport pickle \nimport cv2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.  *Initialize The Preprocessing Function*\n> ","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef normalized_coordinates(filename, width, height, xmin, ymin, xmax, ymax):\n    \"\"\"Take in image coordinates (unnormalized) as input, return normalized values \n    \"\"\"\n    \n    xmin, xmax = xmin / width, xmax / width\n    ymin, ymax = ymin / height, ymax/ height\n\n    width = xmax-xmin\n    height = ymax-ymin\n    x_center = xmin + (width / 2)\n    y_center = ymin + (height / 2)\n\n    return x_center, y_center, width, height\n\ndef write_label(filename, x_center, y_center, width, height):\n    \"\"\"Save image's coordinates in text file named \"filename\"\n    \"\"\"\n    with open(filename, mode='w') as outf:\n        outf.write(f\"{0} {x_center} {y_center} {width} {height}\\n\")\n\ndef parse_xml_tags(data):\n    \"\"\"Parse xml label file, return image file name, and its coordinates as a dictionary\n    \"\"\"\n    tags = ['filename', 'width', 'height', 'xmin', 'ymin', 'xmax', 'ymax']\n    Bs_data = BeautifulSoup(data, \"xml\")\n    d = dict()\n\n    for t in tags:\n        text = Bs_data.find(t).text\n        if all(c.isdigit() for c in text):\n            d[t] = int(text)\n        else:\n            d[t] = text\n    return d\n\ndef build_data(dir_folder, ann_file_list, img_dir):\n    \"\"\"Write xml labels to text file with specifications format, save at 'labels' folder.\n        Move image to 'images' folder\n    \"\"\"\n    images_folder = f\"{dir_folder}/images\"\n    labels_folder = f\"{dir_folder}/labels\"\n    \n    os.makedirs(images_folder, exist_ok = True)\n    os.makedirs(labels_folder, exist_ok = True)\n\n\n    for ann_file in ann_file_list:\n        with open(ann_file, 'r') as f:\n            label = parse_xml_tags(f.read())\n         \n        img_file_name = label['filename']\n        x_center, y_center, width, height = normalized_coordinates(**label)\n         \n        # save at 'labels' folder\n        write_label(f\"{labels_folder}/{img_file_name.split('.')[0]}.txt\", x_center, y_center, width, height)\n         \n         # Move image to 'images' folder\n        shutil.copy(f\"{img_dir}/{img_file_name}\", f\"{images_folder}/{img_file_name}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.  **Loading Dataset images and it's annotation **","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dir_folder = \"/kaggle/working/plate_datasets\"\n\nann_list = glob.glob('/kaggle/input/car-plate-detection/annotations/*')\nbuild_data(dir_folder, ann_list, \"/kaggle/input/car-plate-detection/images\")\n\nann_list = glob.glob('/kaggle/input/number-plate-detection/images/*.xml')\nbuild_data(dir_folder, ann_list, \"/kaggle/input/number-plate-detection/images\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndata = {\n    \"path\": dir_folder,\n    \"train\": \"images\",\n    \"val\": \"\",\n    \"names\": {0: \"car_lisence_plate\"}\n    }\n\nwith open('/kaggle/working/plate_datasets/dataset.yaml', 'w') as outfile:\n    yaml.dump(data, outfile, default_flow_style=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assert len(os.listdir(\"/kaggle/working/plate_datasets/labels\")) == len(os.listdir(\"/kaggle/working/plate_datasets/images\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"  # 3.  **Downloading Yolov5**","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/ultralytics/yolov5  # clone\n%cd yolov5\n!pip install -r requirements.txt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python train.py --img 640 --batch 16 --epochs 15 --data /kaggle/working/plate_datasets/dataset.yaml --weights yolov5s.pt --cache ram","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nresults = plt.imread('/kaggle/working/yolov5/runs/train/exp/confusion_matrix.png')\nplt.imshow(results)\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image, display\n\n# Specify the file path\nimage_path = '/kaggle/working/yolov5/runs/train/exp/results.png'\n\n# Display the image\ndisplay(Image(filename=image_path))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image, display\n\n# Specify the file path\nimg_coo = '/kaggle/working/yolov5/runs/train/exp/labels_correlogram.jpg'\n\n# Display the image\ndisplay(Image(filename=img_coo))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image, display\n\n# Specify the file path\nimg_coo = '/kaggle/working/yolov5/runs/train/exp/labels.jpg'\n\n# Display the image\ndisplay(Image(filename=img_coo))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"4. # **Training Our Model**","metadata":{}},{"cell_type":"code","source":"\nyolo = torch.hub.load('ultralytics/yolov5', 'custom', path='/kaggle/working/yolov5/runs/train/exp/weights/best.pt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.  **Reading The plate Number**","metadata":{}},{"cell_type":"code","source":"def read_plate_number(results, frame, reader):\n    n = len(results)\n    x_shape, y_shape = frame.shape[1], frame.shape[0]\n\n    for i in range(n):\n        row = results[i]  # Assuming results is a list of coordinates\n        confidence_index = -1  # Adjust this index based on your actual data structure\n\n        if row[confidence_index] >= 0.5:  # Take img with 0.5 confidence\n            xmin, ymin, xmax, ymax = row[:4]\n            plate = frame[int(ymin):int(ymax), int(xmin):int(xmax)]\n\n            gray = cv.cvtColor(plate, cv.COLOR_BGR2GRAY)\n            blurred = cv.bilateralFilter(gray, 17, 15, 15)\n            text = reader.readtext(blurred)\n            text = ' '.join([t[1] for t in text])\n\n            plot_img = frame.copy()\n\n            cv.rectangle(plot_img, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (0, 255, 0), 2)  # BBox\n            cv.rectangle(plot_img, (int(xmin), int(ymin - 20)), (int(xmax), int(ymin)), (0, 255, 0), -1)  # Text label background\n            #final_img = cv.putText(plot_img, f\"{text}\", (int(xmin), int(ymin)), cv.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n            return plot_img ,text  \n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reader = easyocr.Reader(['en'])\n\nimage_directory = '/kaggle/input/fifty-states-car-license-plates-dataset/Fifty States License Plates/'\n\nimage_files = [os.path.join(image_directory, file) for file in os.listdir(image_directory) if file.endswith(('.jpg', '.png', '.jpeg'))]\n\nall_coordinates = np.empty((0, 4), dtype=float)  # Assuming each coordinate has 4 values (x_min, y_min, x_max, y_max)\nfinal_imgggg=[]\nplate_img= []\ntext2=[]\nfor img_path in image_files:\n    results = yolo(img_path)\n\n    current_coordinates = results.xyxy[0][:, :-1]\n\n    current_coordinates_cpu = current_coordinates.cpu().numpy()\n\n    if current_coordinates_cpu.shape[1] == 5:\n        current_coordinates_cpu = current_coordinates_cpu[:, :-1]  # Assuming the last column is not needed\n\n    frame = cv2.imread(img_path)\n    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    final_imgggg,predict_text=read_plate_number(current_coordinates_cpu, frame, reader)\n    text2.append(predict_text)\n    plate_img.append(final_imgggg)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6.    **Testing Our Model on Other Dataset**","metadata":{}},{"cell_type":"code","source":"fig, axs = plt.subplots(5, 4, figsize=(18, 18))\n\nfor n, i in enumerate(list(np.random.randint(0, len(plate_img), 20))):\n    plt.subplot(5, 4, n + 1)\n    plt.imshow(plate_img[i])\n    plt.axis('off')\n    plt.title(text2[i])\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(yolo.state_dict(), 'yolo_car_plate.pt')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yolo2 = torch.hub.load('ultralytics/yolov5', 'custom', path='/kaggle/working/yolov5/runs/train/exp/weights/best.pt',force_reload=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yolo.type","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yolo2 ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img=('/kaggle/input/fifty-states-car-license-plates-dataset/Fifty States License Plates/Nebraska.jpg')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result222=yolo2(img)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result222","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_plate_number_image(results, frame, reader):\n    # Assuming results is a list of coordinates for one photo\n    if len(result222) > 0:  # Check if the list is not empty\n        row = result222[0]  # Take the first and only row\n        confidence_index = -1  # Adjust this index based on your actual data structure\n\n        if row[confidence_index] >= 0.5:  # Take img with 0.5 confidence\n            xmin, ymin, xmax, ymax = row[:4]\n            plate = frame[int(ymin):int(ymax), int(xmin):int(xmax)]\n\n            gray = cv.cvtColor(plate, cv.COLOR_BGR2GRAY)\n            blurred = cv.bilateralFilter(gray, 17, 15, 15)\n            text = reader.readtext(blurred)\n            text = ' '.join([t[1] for t in text])\n\n            plot_img = frame.copy()\n\n            cv.rectangle(plot_img, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (0, 255, 0), 2)  # BBox\n            cv.rectangle(plot_img, (int(xmin), int(ymin - 20)), (int(xmax), int(ymin)), (0, 255, 0), -1)  # Text label background\n            #final_img = cv.putText(plot_img, f\"{text}\", (int(xmin), int(ymin)), cv.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n            return plot_img ,text  \n    else:\n        return None, None  # No plate detected\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_imgggg=[]\nplate_img= []\ntext2=[]\n\ncurrent_coordinates = result222.xyxy[0][:, :-1]\n\ncurrent_coordinates_cpu = current_coordinates.cpu().numpy()\n\nif current_coordinates_cpu.shape[1] == 5:\n    current_coordinates_cpu = current_coordinates_cpu[:, :-1]  # Assuming the last column is not needed\n\nframe = cv2.imread(img)\nframe = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\nfinal_imgggg,predict_text=read_plate_number_image(current_coordinates_cpu, frame, reader)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result222","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plate_img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results22 = yolo('/kaggle/input/fifty-states-car-license-plates-dataset/Fifty States License Plates/Alabama.jpg')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results22","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results222","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(plate_img[0])\nplt.axis('off')\nplt.title(text2[0])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}